import streamlit as st
import sqlite3
from datetime import datetime
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
import re

# ==========================
# C·∫§U H√åNH ·ª®NG D·ª§NG
# ==========================
st.set_page_config(
    page_title="Tr·ª£ l√Ω ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát",
    page_icon="üòä",
    layout="centered"
)


# ==========================
# KH·ªûI T·∫†O MODEL
# ==========================
@st.cache_resource
def load_model():
    try:
        model_name = "mr4/phobert-base-vi-sentiment-analysis"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
        return classifier
    except Exception as e:
        st.error(f"L·ªói khi load model: {str(e)}")
        return None


# ==========================
# TI·ªÄN X·ª¨ L√ù TI·∫æNG VI·ªÜT
# ==========================
def preprocess_text(text):
    """Chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát"""
    if not text or len(text.strip()) < 3:
        return None

    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng
    text = text.lower().strip()

    # S·ª≠a c√°c t·ª´ vi·∫øt t·∫Øt/th∆∞·ªùng g·∫∑p
    replacements = {
        ' rat ': ' r·∫•t ',
        ' dc ': ' ƒë∆∞·ª£c ',
        ' ko ': ' kh√¥ng ',
        ' k ': ' kh√¥ng ',
        ' nt ': ' nh∆∞ th·∫ø ',
        ' ntn ': ' nh∆∞ th·∫ø n√†o ',
        ' bt ': ' b√¨nh th∆∞·ªùng ',
        ' do ': ' d·ªü ',
        ' ng ': ' ng∆∞·ªùi ',
        ' hom nay': ' h√¥m nay',
        ' hom qua': ' h√¥m qua',
        ' hom sau': ' h√¥m sau'
    }

    for wrong, correct in replacements.items():
        text = text.replace(wrong, correct)

    # X√≥a kho·∫£ng tr·∫Øng th·ª´a
    text = re.sub(r'\s+', ' ', text)

    return text.strip()


# ==========================
# X·ª¨ L√ù DATABASE
# ==========================
def init_db():
    """Kh·ªüi t·∫°o database SQLite"""
    conn = sqlite3.connect('sentiment_history.db')
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS sentiments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            text TEXT NOT NULL,
            sentiment TEXT NOT NULL,
            timestamp TEXT NOT NULL
        )
    ''')
    conn.commit()
    conn.close()


def save_to_db(text, sentiment):
    """L∆∞u k·∫øt qu·∫£ v√†o database"""
    conn = sqlite3.connect('sentiment_history.db')
    c = conn.cursor()
    timestamp = datetime.now().isoformat()
    c.execute(
        "INSERT INTO sentiments (text, sentiment, timestamp) VALUES (?, ?, ?)",
        (text, sentiment, timestamp)
    )
    conn.commit()
    conn.close()


def get_history():
    """L·∫•y l·ªãch s·ª≠ ph√¢n lo·∫°i"""
    conn = sqlite3.connect('sentiment_history.db')
    c = conn.cursor()
    c.execute(
        "SELECT text, sentiment, timestamp FROM sentiments ORDER BY timestamp DESC LIMIT 50"
    )
    results = c.fetchall()
    conn.close()
    return results


# ==========================
# GIAO DI·ªÜN CH√çNH
# ==========================
def main():
    # Kh·ªüi t·∫°o database
    init_db()

    # Header
    st.title("üòä Tr·ª£ l√Ω ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát")
    st.markdown("---")
    st.markdown("""
        <style>
        .stTextArea [data-baseweb="textarea"] {
            border-color: #cccccc !important;
        }
        </style>
        """, unsafe_allow_html=True)
    # Load model v·ªõi progress bar
    with st.spinner("ƒêang kh·ªüi t·∫°o model..."):
        classifier = load_model()

    if classifier is None:
        st.error("Kh√¥ng th·ªÉ kh·ªüi t·∫°o model. Vui l√≤ng th·ª≠ l·∫°i!")
        return

    # Khu v·ª±c nh·∫≠p li·ªáu
    st.subheader("üìù Nh·∫≠p c√¢u ti·∫øng Vi·ªát c·∫ßn ph√¢n lo·∫°i")
    st.markdown("""
        <style>
        textarea:focus {
            border: 1px solid #ccc !important;
            box-shadow: none !important;
        }
        </style>
    """, unsafe_allow_html=True)
    user_input = st.text_area(
        "Nh·∫≠p c√¢u c·ªßa b·∫°n t·∫°i ƒë√¢y:",
        placeholder="V√≠ d·ª•: H√¥m nay t√¥i r·∫•t vui...",
        height=100,
        value=""  # ƒë·∫£m b·∫£o kh√¥ng ph·∫£i None
    )

    # N√∫t ph√¢n lo·∫°i
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        analyze_btn = st.button("üîç Ph√¢n lo·∫°i c·∫£m x√∫c", use_container_width=True)

    # X·ª≠ l√Ω khi nh·∫•n n√∫t ph√¢n lo·∫°i
    if analyze_btn:
        if not user_input.strip():
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u tr∆∞·ªõc khi ph√¢n t√≠ch!")
        elif len(user_input.strip()) < 3:
            st.warning("‚ö†Ô∏è C√¢u qu√° ng·∫Øn, vui l√≤ng nh·∫≠p √≠t nh·∫•t 3 k√Ω t·ª±!")

        else:
            with st.spinner("ƒêang ph√¢n t√≠ch c·∫£m x√∫c..."):
                # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
                processed_text = preprocess_text(user_input)

                if not processed_text:
                    st.error("‚ùå C√¢u nh·∫≠p v√†o kh√¥ng h·ª£p l·ªá!")
                    return

                try:
                    # Ph√¢n lo·∫°i c·∫£m x√∫c
                    result = classifier(processed_text)[0]

                    # √Ånh x·∫° nh√£n c·∫£m x√∫c
                    label_map = {
                        'T√≠ch c·ª±c': 'T√çCH C·ª∞C üòä',
                        'Ti√™u c·ª±c': 'TI√äU C·ª∞C üòû',
                        'Trung t√≠nh': 'TRUNG T√çNH üòê'
                    }

                    sentiment = result['label']
                    score = result['score']

                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    st.markdown("---")
                    st.subheader("üéØ K·∫øt qu·∫£ ph√¢n lo·∫°i")

                    # Hi·ªÉn th·ªã v·ªõi m√†u s·∫Øc t∆∞∆°ng ·ª©ng
                    if sentiment == 'T√≠ch c·ª±c':
                        st.success(f"**C·∫£m x√∫c:** {label_map[sentiment]}")
                    elif sentiment == 'Ti√™u c·ª±c':
                        st.error(f"**C·∫£m x√∫c:** {label_map[sentiment]}")
                    else:
                        st.info(f"**C·∫£m x√∫c:** {label_map[sentiment]}")
                    st.write(f"**ƒê·ªô tin c·∫≠y:** {score:.2%}")
                    st.write(f"**C√¢u ƒë√£ x·ª≠ l√Ω:** {processed_text}")

                    # L∆∞u v√†o database
                    save_to_db(user_input, sentiment)

                    st.success("‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o l·ªãch s·ª≠!")

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch: {str(e)}")

    # Hi·ªÉn th·ªã l·ªãch s·ª≠
    st.markdown("---")
    st.subheader("üìä L·ªãch s·ª≠ ph√¢n lo·∫°i")
    history = get_history()
    if history:
        # Hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng b·∫£ng
        for i, (text, sentiment, timestamp) in enumerate(history[:10], 1):
            # ƒê·ªãnh d·∫°ng th·ªùi gian
            dt = datetime.fromisoformat(timestamp)
            time_str = dt.strftime("%d/%m/%Y %H:%M")

            # Hi·ªÉn th·ªã v·ªõi icon t∆∞∆°ng ·ª©ng
            icons = {'T√≠ch c·ª±c': 'üòä', 'Ti√™u c·ª±c': 'üòû', 'Trung t√≠nh': 'üòê'}
            icon = icons.get(sentiment, '‚ùì')

            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**{i}. {text}**")
                with col2:
                    st.write(f"{icon} {sentiment} - {time_str}")
                st.markdown("---")
    else:
        st.info("üìù Ch∆∞a c√≥ l·ªãch s·ª≠ ph√¢n lo·∫°i n√†o.")


# ==========================
# CH·∫†Y ·ª®NG D·ª§NG
# ==========================
if __name__ == "__main__":
    main()